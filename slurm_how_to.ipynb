{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello World in `srun`\n",
    "Below is the absolute simplest way to run a job on Cheaha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!srun --pty echo \"Hello World!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `srun` is great for setting up an interactive job using `--pty`, it doesn't scale well to repeated use or for intricate jobs. It's hard to remember, share and modify. A job created with `srun` will also terminate if you lose your connection to Cheaha!\n",
    "\n",
    "Prefer using `sbatch` over `srun`. With `sbatch` you write a script with one resource request per line, and can sequence multiple tasks. These tasks can take the form of trackable job steps using `srun`, or just using bare shell commands. It is also possible to use job arrays to submit many similar jobs at the same time. Using `sbatch` makes it easy to\n",
    "\n",
    "- share with collaborators\n",
    "- keep track of versions -- repeatability!\n",
    "- read and modify\n",
    "- run multiple commands in one job\n",
    "- run many of the same type of job with a single submission\n",
    "- won't terminate if you lose connection\n",
    "\n",
    "Remember, `srun` is only useful for interactive jobs, one-off commands, and sub-tasks inside an `sbatch` job. In contrast `sbatch` is meant for repeatable, collaborative Research Computing!\n",
    "\n",
    "Let's take a look at how to use `sbatch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `sbatch`\n",
    "Before we get started learning how to write sbatch scripts, there are some good practices to consider. Taken from the [Zen of Python](https://www.python.org/dev/peps/pep-0020/), we see that \"explicit is better than implicit.\" This means, for `sbatch` scripts, don't rely on default values. Instead, be explicit about your intent for the job submission. Then other people, and yourself at a later date, will be able to understand what you meant. Always...\n",
    "\n",
    "- give your jobs meaningful names with `--job-name`\n",
    "- specify your output logs with `--output` and `--error`\n",
    "- choose partition and resources carefully and explicitly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello World\n",
    "Here is a sample script which waits a few seconds after submission, then `echo`s a couple of lines to an output file.\n",
    "\n",
    "The cell below uses the `ipython` magic `%%bash` to run the contents of the cell using the `bash` shell, as though typed at a terminal. The `cat` command concatenates things to a stream. The `> \"hello_world.sh\"` means we are redirecting the output of `cat` to the file `hello_world.sh`. The `<<EOT` starts a `heredoc` and redirects it into `cat`. A `heredoc` is what it sounds like, a \"fake\" file we are making up as we go. Our heredoc starts on the line after `cat` and ends on the line before `EOT`.\n",
    "\n",
    "Basically, we're writing what you see into a file that we can use later. When you write a script on your own later, you won't need to do this. Instead, just open your favorite text editor and start with the line `#! /bin/bash` and up to, but not including, `EOT` at the end. We have the extra parts here so you can see the contents of the file directly in Jupyter without having to open the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat <<EOT > \"hello_world.sh\"\n",
    "#! /bin/bash\n",
    "\n",
    "## BOOKKEEPING\n",
    "#SBATCH --job-name=hello_world\n",
    "# %x means \"put the job-name here\"\n",
    "#SBATCH --output=%x.log\n",
    "#SBATCH --error=%x.log\n",
    "\n",
    "## RESOURCES\n",
    "#SBATCH --partition=express\n",
    "#SBATCH --time=00:01:00\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --mem=256M\n",
    "\n",
    "# PAYLOAD\n",
    "sleep 15\n",
    "echo \"hello world\"\n",
    "echo \"hi again\"\n",
    "EOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that the contents of `hello_world.sh` are what we expect using `cat` again. The `!` symbol is `ipython` magic that runs the line as a shell command. Make sure the output matches the cell above!\n",
    "\n",
    "So `%%bash` runs an entire cell in `bash` and `!` runs a single line in `bash`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#! /bin/bash\r\n",
      "\r\n",
      "## BOOKKEEPING\r\n",
      "#SBATCH --job-name=hello_world\r\n",
      "# %x means \"put the job-name here\"\r\n",
      "#SBATCH --output=%x.log\r\n",
      "#SBATCH --error=%x.log\r\n",
      "\r\n",
      "## RESOURCES\r\n",
      "#SBATCH --partition=express\r\n",
      "#SBATCH --time=00:01:00\r\n",
      "#SBATCH --ntasks=1\r\n",
      "#SBATCH --cpus-per-task=1\r\n",
      "#SBATCH --mem=256M\r\n",
      "\r\n",
      "# PAYLOAD\r\n",
      "sleep 5\r\n",
      "echo \"hello world\"\r\n",
      "echo \"hi again\"\r\n"
     ]
    }
   ],
   "source": [
    "!cat \"hello_world.sh\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are sure our `hello_world.sh` file is prepared, we can submit the script to the slurm queue using sbatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 10147563\r\n"
     ]
    }
   ],
   "source": [
    "!sbatch \"hello_world.sh\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that the job made it into the queue using `squeue`. You'll want to do this quickly because the job will only be around for about 15 seconds (see the line with `sleep 15`).\n",
    "\n",
    "You should also see the `ood-jupyter` job you are using to run these cells as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\r\n",
      "          10146968     short ood-jupy    wwarr  R    2:18:22      1 c0066\r\n"
     ]
    }
   ],
   "source": [
    "!squeue -u $USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify the output of the script using `cat` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\r\n",
      "hi again\r\n"
     ]
    }
   ],
   "source": [
    "!cat \"hello_world.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you now know the workflow for using `sbatch` scripts! There are a couple more commands that you may find useful. Next let's see what happens if you submit a job by mistake and need to cancel it to free up resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to cancel a running job\n",
    "Below we'll run the exact same workflow as we did for `hello_world.sh`. We'll call this one `cancelme.sh` because we're going to learn how to cancel a job. We accidentally made the job sleep for 3600 seconds (1 hour) before getting to the good part. We meant to only wait 15 seconds, but we didn't realize it until after we submitted the job. Oops!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --out t\n",
    "cat <<EOT > \"cancelme.sh\"\n",
    "#! /bin/bash\n",
    "\n",
    "## BOOKKEEPING\n",
    "#SBATCH --job-name=cancelme\n",
    "# %x means \"put the job-name here\"\n",
    "#SBATCH --output=%x.log\n",
    "#SBATCH --error=%x.log\n",
    "\n",
    "## RESOURCES\n",
    "#SBATCH --partition=express\n",
    "#SBATCH --time=01:00:00\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --mem=256M\n",
    "\n",
    "# PAYLOAD\n",
    "sleep 3600  ## Oops we meant 15 seconds!\n",
    "echo \"finally!\"\n",
    "EOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#! /bin/bash\r\n",
      "\r\n",
      "## BOOKKEEPING\r\n",
      "#SBATCH --job-name=cancelme\r\n",
      "# %x means \"put the job-name here\"\r\n",
      "#SBATCH --output=%x.log\r\n",
      "#SBATCH --error=%x.log\r\n",
      "\r\n",
      "## RESOURCES\r\n",
      "#SBATCH --partition=express\r\n",
      "#SBATCH --time=01:00:00\r\n",
      "#SBATCH --ntasks=1\r\n",
      "#SBATCH --cpus-per-task=1\r\n",
      "#SBATCH --mem=256M\r\n",
      "\r\n",
      "# PAYLOAD\r\n",
      "sleep 3600  ## Oops we meant 15 seconds!\r\n",
      "echo \"finally!\"\r\n"
     ]
    }
   ],
   "source": [
    "!cat \"cancelme.sh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 10148017\r\n"
     ]
    }
   ],
   "source": [
    "!sbatch cancelme.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\r\n",
      "          10148017   express cancelme    wwarr  R       0:00      1 c0094\r\n",
      "          10146968     short ood-jupy    wwarr  R    2:22:41      1 c0066\r\n"
     ]
    }
   ],
   "source": [
    "!squeue -u $USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `cancelme` job is going to take an hour to clear from the queue, meanwhile we're just using up shared resources and worsening our job priority! Let's be good HPC citizens and cancel that mistaken job!\n",
    "\n",
    "To cancel the job you'll need to modify the cell below. Where you see `[jobid]` below, replace it with the job id from our submission. Think `sbatch cancelme.sh`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scancel [jobid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we actually canceled the job. We can do that by making sure it's not in the queue any longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\r\n",
      "          10146968     short ood-jupy    wwarr  R    1:12:54      1 c0066\r\n"
     ]
    }
   ],
   "source": [
    "!squeue -u $USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to see past jobs\n",
    "- `sacct`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to be efficient\n",
    "- `seff`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello World -- Arrays!\n",
    "`--array` flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to request GPUs\n",
    "`--gres` flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different ways to request resources\n",
    "- `--ntasks` vs `--nodes` + `--ntasks-per-node`\n",
    "- `--cpus-per-task`\n",
    "- `--mem-per-cpu` vs `--mem`\n",
    "- Where to find up-to-date `--partition` info\n",
    "- Time formats for `--time`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other `sbatch` flags that may be useful\n",
    "- `--mail-type` and `--mail-user`\n",
    "- `-D` or `--chdir`\n",
    "- `--export` and `--export-file` control which environment vars are exported\n",
    "- `--no-requeue` avoid requeueing if job is terminated, contrast with `--requeue`\n",
    "- `--parsable` can help with automation\n",
    "- `--test-only` to estimate when job will start processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful environment variables to use in a script\n",
    "- SLURM_ARRAY_JOB_ID, SLURM_ARRAY_TASK_COUNT, SLURM_ARRAY_TASK_ID\n",
    "- SLURM_CPUS_PER_TASK, SLURM_CPUS_ON_NODE\n",
    "- SLURM_JOB_NAME, SLURM_JOB_ID\n",
    "- SLURM_MEM_PER_CPU, SLURM_MEM_PER_NODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `srun` inside `sbatch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
